{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c894267f",
   "metadata": {},
   "source": [
    "### 02 LangGraph/LangChain によるLLMチャット\n",
    "- Google Colabに必要なライブラリをインストール\n",
    "- transformersを使ってLLMモデルをHugging Faceから読み込み\n",
    "- LangGraphによるLLMのメモリ管理\n",
    "- LangGraph/LangChainによるチャット\n",
    "- MCPサーバ(ddg-search)によるweb検索（今回（notebook 02）はユーザがMCPサーバを実行）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2072c39",
   "metadata": {},
   "source": [
    "**Google Colabに必要なライブラリをインストール**\n",
    "- 1行にまとめることで pip が全パッケージの依存関係を一括解決する。\n",
    "- 分割すると後勝ちで依存関係が壊れるリスクがある。\n",
    "  > （transformersとlangchain-huggingfaceで、huggingface-hubのバージョンが衝突する等）\n",
    "- NOTE: Colab では uv ではなく pip を使う。\n",
    "  > uv は依存解決の過程でnumpy 等をアップグレードし、プリインストール済みの scipy 等を壊すため。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23577a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-5.1.0-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.7)\n",
      "Collecting duckduckgo-mcp-server\n",
      "  Downloading duckduckgo_mcp_server-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: mcp in /usr/local/lib/python3.12/dist-packages (1.26.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.3.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cpu)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.2.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
      "INFO: pip is looking at multiple versions of langchain-huggingface to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-1.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Downloading langchain_huggingface-1.0.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Downloading langchain_huggingface-1.0.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
      "  Downloading langchain_huggingface-0.3.0-py3-none-any.whl.metadata (996 bytes)\n",
      "  Downloading langchain_huggingface-0.2.0-py3-none-any.whl.metadata (941 bytes)\n",
      "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-huggingface to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_huggingface-0.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Downloading langchain_huggingface-0.0.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Downloading langchain_huggingface-0.0.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langchain\n",
      "  Downloading langchain-1.2.8-py3-none-any.whl.metadata (5.0 kB)\n",
      "  Downloading langchain-1.2.7-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.2.6-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.2.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.2.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.2.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.2.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.1.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.1.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.1.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.1.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.0.8-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.0.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.0.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.0.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langchain-1.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langchain-1.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.83-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.6.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.46)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (0.14.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.13.3 in /usr/local/lib/python3.12/dist-packages (from duckduckgo-mcp-server) (4.13.5)\n",
      "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.12/dist-packages (from mcp) (4.12.1)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp) (0.4.3)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp) (4.26.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp) (2.12.0)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp) (2.11.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp) (0.0.22)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp) (3.2.0)\n",
      "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp) (0.50.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp) (0.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp) (0.40.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=4.5->mcp) (3.11)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.13.3->duckduckgo-mcp-server) (2.8.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp) (0.30.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
      "INFO: pip is looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langgraph-checkpoint<5.0.0,>=2.1.0 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-4.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langgraph_checkpoint-3.0.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "  Downloading langgraph_checkpoint-2.1.2-py3-none-any.whl.metadata (4.2 kB)\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pip>=25.2 (from langchain-text-splitters<1.0.0,>=0.3.9->langchain)\n",
      "  Downloading pip-26.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "INFO: pip is still looking at multiple versions of langgraph-prebuilt to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-1.0.7-py3-none-any.whl.metadata (7.4 kB)\n",
      "  Downloading langgraph-1.0.6-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-1.0.6-py3-none-any.whl.metadata (5.2 kB)\n",
      "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "  Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
      "  Downloading langgraph_prebuilt-1.0.3-py3-none-any.whl.metadata (5.2 kB)\n",
      "  Downloading langgraph_prebuilt-1.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-1.0.5-py3-none-any.whl.metadata (7.4 kB)\n",
      "  Downloading langgraph-1.0.4-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.2.15-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "  Downloading langgraph-1.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "  Downloading langgraph-1.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-1.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]>=1.3.0->duckduckgo-mcp-server) (1.2.1)\n",
      "Requirement already satisfied: typer>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from mcp[cli]>=1.3.0->duckduckgo-mcp-server) (0.21.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp) (43.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.3.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp) (8.3.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp) (2.0.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.16.0->mcp[cli]>=1.3.0->duckduckgo-mcp-server) (13.9.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp) (3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.16.0->mcp[cli]>=1.3.0->duckduckgo-mcp-server) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer>=0.16.0->mcp[cli]>=1.3.0->duckduckgo-mcp-server) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.16.0->mcp[cli]>=1.3.0->duckduckgo-mcp-server) (0.1.2)\n",
      "Downloading transformers-5.1.0-py3-none-any.whl (10.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
      "Downloading langchain_core-0.3.83-py3-none-any.whl (458 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.9/458.9 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph-1.0.1-py3-none-any.whl (155 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langgraph_prebuilt-1.0.1-py3-none-any.whl (28 kB)\n",
      "Downloading duckduckgo_mcp_server-0.1.1-py3-none-any.whl (6.5 kB)\n",
      "Downloading langgraph_sdk-0.2.15-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: packaging, langgraph-sdk, bitsandbytes, langchain-core, transformers, langgraph-checkpoint, langchain-text-splitters, langchain-huggingface, langgraph-prebuilt, langchain, duckduckgo-mcp-server, langgraph\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 26.0\n",
      "    Uninstalling packaging-26.0:\n",
      "      Successfully uninstalled packaging-26.0\n",
      "  Attempting uninstall: langgraph-sdk\n",
      "    Found existing installation: langgraph-sdk 0.3.3\n",
      "    Uninstalling langgraph-sdk-0.3.3:\n",
      "      Successfully uninstalled langgraph-sdk-0.3.3\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 1.2.8\n",
      "    Uninstalling langchain-core-1.2.8:\n",
      "      Successfully uninstalled langchain-core-1.2.8\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 5.0.0\n",
      "    Uninstalling transformers-5.0.0:\n",
      "      Successfully uninstalled transformers-5.0.0\n",
      "  Attempting uninstall: langgraph-checkpoint\n",
      "    Found existing installation: langgraph-checkpoint 4.0.0\n",
      "    Uninstalling langgraph-checkpoint-4.0.0:\n",
      "      Successfully uninstalled langgraph-checkpoint-4.0.0\n",
      "  Attempting uninstall: langgraph-prebuilt\n",
      "    Found existing installation: langgraph-prebuilt 1.0.7\n",
      "    Uninstalling langgraph-prebuilt-1.0.7:\n",
      "      Successfully uninstalled langgraph-prebuilt-1.0.7\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 1.2.8\n",
      "    Uninstalling langchain-1.2.8:\n",
      "      Successfully uninstalled langchain-1.2.8\n",
      "  Attempting uninstall: langgraph\n",
      "    Found existing installation: langgraph 1.0.7\n",
      "    Uninstalling langgraph-1.0.7:\n",
      "      Successfully uninstalled langgraph-1.0.7\n",
      "Successfully installed bitsandbytes-0.49.1 duckduckgo-mcp-server-0.1.1 langchain-0.3.27 langchain-core-0.3.83 langchain-huggingface-0.3.1 langchain-text-splitters-0.3.11 langgraph-1.0.1 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.1 langgraph-sdk-0.2.15 packaging-25.0 transformers-5.1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "f88dcaf1233e41aa9870cf074e383204",
       "pip_warning": {
        "packages": [
         "packaging"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Google Colabに必要なライブラリをインストールする。\n",
    "# 1行にまとめることで pip が全パッケージの依存関係を一括解決する。\n",
    "# 分割すると後勝ちで依存関係が壊れるリスクがある。\n",
    "# （transformersとlangchain-huggingfaceで、huggingface-hubのバージョンが衝突する等）\n",
    "# NOTE: Colab では uv ではなく pip を使う。uv は依存解決の過程で\n",
    "#       numpy 等をアップグレードし、プリインストール済みの scipy 等を壊すため。\n",
    "%pip install -U transformers accelerate bitsandbytes \\\n",
    "     langchain langchain-huggingface langgraph \\\n",
    "     duckduckgo-mcp-server mcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b944db5",
   "metadata": {},
   "source": [
    "**transformersを使ってLLMモデルをHugging Faceから読み込み**\n",
    "\n",
    "##### LLM バックエンドの選定\n",
    "\n",
    "このリポジトリでは **transformers + bitsandbytes** を採用。\n",
    "- Colab GPU との相性が良い\n",
    "- 量子化などの細かい設定が可能\n",
    "- 非同期処理に対応\n",
    "\n",
    "**将来の本番環境向け:**\n",
    "- 非同期/スケーラビリティ重視が必要となる場合、Ollamaなどサーバ管理されたものを使用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aea36c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b46f96fc24886a825836643b648c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/340 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデルのメモリ消費量: 1.86 GB\n"
     ]
    }
   ],
   "source": [
    "# transformersを使ってLLMモデルをHugging Faceから読み込みする。\n",
    "import torch  # type: ignore\n",
    "from transformers import (  # type: ignore\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,  # noqa: F401\n",
    "    pipeline,\n",
    ")  # type: ignore\n",
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace  # type: ignore\n",
    "\n",
    "model_name = \"unsloth/gemma-3-1b-it\"  # Hugging Faceのモデルの名称\n",
    "\n",
    "# LLMモデルの量子化の設定\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,  # 4 ビットに量子化された形式で読み込むように指定\n",
    "#     bnb_4bit_quant_type=\"nf4\",  # 4 ビット量子化のデータ型として NF4 を指定\n",
    "#     bnb_4bit_use_double_quant=True,  # 二重量子化の指定\n",
    "#     bnb_4bit_compute_dtype=torch.bfloat16,  # 計算時のデータ型を指定\n",
    "# )\n",
    "\n",
    "# LLMに生成させる文章の計算条件\n",
    "generation_params = {\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.8,\n",
    "    \"top_k\": 40,\n",
    "    \"top_p\": 0.9,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"max_new_tokens\": 512,\n",
    "}\n",
    "\n",
    "# LLMモデルの読み込み\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,  # Hugging Faceから読み込みするモデルの名称\n",
    "    # quantization_config=quantization_config,\n",
    "    dtype=torch.bfloat16,  # 読み込みするモデルのデータ型（transformers 4.x では torch_dtype）\n",
    "    device_map=\"auto\",  # 読み込んだモデルを CPU / GPUに自動で割り当てする指示\n",
    ")\n",
    "\n",
    "# transformersのパイプライン\n",
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,  # 入力プロンプトを出力に含めない\n",
    ")\n",
    "\n",
    "# LangChainのHuggingFaceパイプラインに接続\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline, pipeline_kwargs=generation_params)\n",
    "\n",
    "# チャットモデルインターフェースとして接続（チャットテンプレート対応）\n",
    "chat_llm = ChatHuggingFace(llm=llm)\n",
    "\n",
    "# モデルのメモリ消費量（バイト）を取得し、GBに変換して表示\n",
    "memory_footprint_bytes = model.get_memory_footprint()\n",
    "memory_footprint_gb = memory_footprint_bytes / (1024 * 1024 * 1024)\n",
    "print(f\"モデルのメモリ消費量: {memory_footprint_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3584f48",
   "metadata": {},
   "source": [
    "**LangGraphによるLLMのメモリ管理**\n",
    "- chat_nodeで、前のセルで作成したLLMモデルを呼び出した際の処理を設定。\n",
    "  > 今回は人間のプロンプトをLLMに入力して、LLMから応答を取得する処理。\n",
    "- LangGraphのグラフを構築し、ノードとエッジを設定し、グラフをcompileする。\n",
    "  > 今回は単純だが、各処理をつなげて自動化させる場合に効果を発揮する。\n",
    "- InMemorySaverを使用して、LLMとの会話をメモリに保存させる。\n",
    "  > LLMとのチャット履歴が保持されるようになる。\n",
    "- 作成したグラフを図示する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9289c3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LangGraph によるメモリ付きチャットグラフの構築\n",
    "# InMemorySaver を使って、スレッド（thread_id）ごとに会話履歴を保持する\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END  # type: ignore\n",
    "from langgraph.checkpoint.memory import InMemorySaver  # type: ignore\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "# チャットノード：現在の会話履歴を LLM に送信し、返答を生成\n",
    "def chat_node(state: MessagesState):\n",
    "    response = chat_llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# グラフの構築\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"chat\", chat_node)\n",
    "graph.add_edge(START, \"chat\")\n",
    "graph.add_edge(\"chat\", END)\n",
    "\n",
    "# InMemorySaver：スレッドごとに会話履歴をインメモリで保持\n",
    "memory = InMemorySaver()\n",
    "app = graph.compile(checkpointer=memory)\n",
    "\n",
    "# 構築したグラフを図示\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7046c4",
   "metadata": {},
   "source": [
    "**LangGraph/LangChainによるチャット**\n",
    "- SystemMessageでシステムプロンプトを、HumanMessageでユーザのプロンプトを設定する。\n",
    "- configで指定したthread_idごとに会話履歴が保持される。\n",
    "- 2回目の質問で前の会話を踏まえた回答が返れば、メモリが正常に動作している証拠。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30341046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1回目の返答 ===\n",
      "日本で一番高い山は富士山です。\n",
      "\n",
      "富士山は、山梨県と静岡県にまたがっています。標高は3,776.24mです。\n",
      "\n",
      "=== 2回目の返答 ===\n",
      "私の名前はAIです。\n",
      "\n",
      "先ほど答えた山の高さは3,776.24メートルです。\n"
     ]
    }
   ],
   "source": [
    "# マルチターン会話のテスト\n",
    "# 同じ thread_id でLLMを複数回呼び出すと、会話履歴が自動的に保持される\n",
    "from langchain_core.messages import HumanMessage, SystemMessage  # type: ignore\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"thread_1\"}}\n",
    "\n",
    "# 1回目の質問（システムプロンプト付き）\n",
    "response1 = app.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            SystemMessage(content=\"日本語で回答してください。\"),\n",
    "            HumanMessage(content=\"私はジョンです。日本で一番高い山は？\"),\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "print(\"=== 1回目の返答 ===\")\n",
    "print(response1[\"messages\"][-1].content)\n",
    "\n",
    "# 2回目の質問（前の会話を踏まえて回答できれば、メモリが動作している証拠）\n",
    "response2 = app.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(\n",
    "                content=\"私の名前は何ですか？先ほど答えた山の高さは何メートルですか？\"\n",
    "            ),\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "print(\"\\n=== 2回目の返答 ===\")\n",
    "print(response2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d97caed",
   "metadata": {},
   "source": [
    "**MCPサーバ（duckduckgo-mcp-server）によるWeb検索**\n",
    "- MCPサーバ（duckduckgo-mcp-server）を stdio 経由で起動し、検索ツールを取得する。\n",
    "  > AIに自律的に検索ツールを使わせるのではなく、今回（notebook 02）はユーザがMCPサーバを実行。\n",
    "- 検索結果をコンテキストとして LLM に渡し、回答を生成させる。\n",
    "  > gemma-3-1b はツールコール非対応のため、検索→LLM回答の2段構成とする。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b73da",
   "metadata": {},
   "source": [
    "**MCPサーバ設定の補足**\n",
    "\n",
    "github に記載されているMCP接続の設定は以下\n",
    "> \"mcpServers\": {\"ddg-search\": {\"command\": \"uvx\", \"args\": [\"duckduckgo-mcp-server\"]}}\n",
    "\n",
    "今回は、pip install済なので、command=\"duckduckgo-mcp-server\" で直接起動。uvx経由ではないので、args=[] としてよい。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d145d2e0",
   "metadata": {},
   "source": [
    "**stdio_client接続の補足**\n",
    "\n",
    "async with stdio_client(server_params) as (read, write):を、次に修正している。\n",
    "  > async with stdio_client(server_params, errlog=open(os.devnull, \"w\")) as (read, write):\n",
    "\n",
    "これはColab環境特有の処置で、Colabの内部構造が標準的なstderrに対応していないため。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3u7ictw8s0m",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCPサーバ（duckduckgo-mcp-server）に接続して検索し、結果をLLMに渡す\n",
    "# Colab環境ではasyncioのインポートなしで非同期処理（async/await）が使用可能\n",
    "# 通常のPython環境では、asyncioのインポートが必要\n",
    "import os\n",
    "\n",
    "from mcp import ClientSession, StdioServerParameters  # type: ignore\n",
    "from mcp.client.stdio import stdio_client  # type: ignore\n",
    "from langchain_core.messages import HumanMessage, SystemMessage  # type: ignore\n",
    "\n",
    "# MCPサーバへの接続パラメータ（stdio 経由で起動）\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"duckduckgo-mcp-server\",\n",
    "    args=[],\n",
    ")\n",
    "\n",
    "query = \"2025年 日本の総人口\"\n",
    "\n",
    "# MCPサーバに接続し、検索ツールを取得して実行\n",
    "# NOTE: Colab の stderr は fileno() 未対応のため、errlog をファイルに迂回する\n",
    "async with stdio_client(server_params, errlog=open(os.devnull, \"w\")) as (read, write):\n",
    "    async with ClientSession(read, write) as session:\n",
    "        await session.initialize()\n",
    "\n",
    "        # MCPサーバが提供するツール一覧を表示\n",
    "        tools = await session.list_tools()\n",
    "        print(\"=== 利用可能なツール ===\")\n",
    "        for t in tools.tools:\n",
    "            print(f\"  - {t.name}: {t.description}\")\n",
    "\n",
    "        # 検索ツールを実行（max_results で検索結果数を制限）\n",
    "        result = await session.call_tool(\"search\", {\"query\": query, \"max_results\": 3})\n",
    "\n",
    "# 検索結果を取得\n",
    "search_results = result.content[0].text\n",
    "print(\"\\n=== 検索結果 ===\")\n",
    "print(search_results)\n",
    "\n",
    "# 検索結果をコンテキストとしてLLMに質問\n",
    "config = {\"configurable\": {\"thread_id\": \"thread_search\"}}\n",
    "response = app.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            SystemMessage(\n",
    "                content=\"以下の検索結果をもとに、ユーザの質問に日本語で簡潔に回答してください。\"\n",
    "            ),\n",
    "            HumanMessage(content=f\"質問: {query}\\n\\n検索結果:\\n{search_results}\"),\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")\n",
    "print(\"\\n=== LLMの回答 ===\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
