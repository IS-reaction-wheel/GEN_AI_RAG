{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 WebサーチをするAIエージェント\n",
    "#### 03_02 Workflow（Ollama）\n",
    "gpt-oss:20b＋MCPサーバ構成のため、**Colab GPU は L4 を使用すること。**\n",
    "- 必要なライブラリをインストール\n",
    "- Google Colab に Ollama をセットアップ\n",
    "- ChatOllama で LLM に接続\n",
    "- MCPサーバ（ddg-search）によるweb検索の実装\n",
    "- LangGraph による Workflow の実装\n",
    "  1. ユーザの質問を入力。\n",
    "  2. ユーザの質問に回答するためのタスク分割, 作成。\n",
    "  3. MCPサーバ（ddg-search）によるweb検索。\n",
    "  4. web検索を終えて回答作成に進むか判断。再調査なら 3 に戻る。\n",
    "  5. ユーザへの回答の作成と提示。\n",
    "- 動作確認\n",
    "\n",
    "AIエージェントワークフローで参考にした設計\n",
    "> [現場で活用するためのAIエージェント実践入門  chapter 4](https://github.com/masamasa59/genai-agent-advanced-book/tree/main/chapter4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**必要なライブラリをインストール**\n",
    "- 1行にまとめることで pip が全パッケージの依存関係を一括解決する。\n",
    "- 分割すると後勝ちで依存関係が壊れるリスクがある。\n",
    "- NOTE: Colab では uv ではなく pip を使う。\n",
    "> uv は依存解決の過程で numpy 等をアップグレードし、プリインストール済みの scipy 等を壊すため。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab に必要なライブラリをインストールする。\n",
    "# 1行にまとめることで pip が全パッケージの依存関係を一括解決する。\n",
    "# NOTE: Colab では uv ではなく pip を使う。uv は依存解決の過程で\n",
    "#       numpy 等をアップグレードし、プリインストール済みの scipy 等を壊すため。\n",
    "# NOTE: langchain 関連は 1.x 系に明示的に指定する。\n",
    "#       Colab プリインストールの 0.3.x が残ると langchain-mcp-adapters が動作しない。\n",
    "# Pythonのリストとして定義することで、Pylanceの警告を防ぎ、可読性を高める。\n",
    "\n",
    "# fmt: off\n",
    "pkgs = [\n",
    "    \"ollama\", \"langchain-ollama\",\n",
    "    \"langchain>=1.2.8\", \"langchain-core>=1.2.8\", \"langgraph>=1.0.7\",\n",
    "    \"langchain-mcp-adapters>=0.2.1\", \"duckduckgo-mcp-server\", \"mcp\",\n",
    "]\n",
    "# fmt: on\n",
    "\n",
    "# リストを結合して pip に渡す\n",
    "# magic command内で {変数} を使うと展開される機能を利用\n",
    "%pip install -U -q {\" \".join(pkgs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Google Colab に Ollama をセットアップ**\n",
    "- Ollama のインストール・起動・モデルのダウンロードを行う。\n",
    "- 詳細は [01_connect_oss_llm.ipynb](01_connect_oss_llm.ipynb) を参照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package zstd.\n",
      "(Reading database ... 121852 files and directories currently installed.)\n",
      "Preparing to unpack .../zstd_1.4.8+dfsg-3build1_amd64.deb ...\n",
      "Unpacking zstd (1.4.8+dfsg-3build1) ...\n",
      "Setting up zstd (1.4.8+dfsg-3build1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      ">>> Installing ollama to /usr/local\n",
      ">>> Downloading ollama-linux-amd64.tar.zst\n",
      "######################################################################## 100.0%\n",
      ">>> Creating ollama user...\n",
      ">>> Adding ollama user to video group...\n",
      ">>> Adding current user to ollama group...\n",
      ">>> Creating ollama systemd service...\n",
      "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
      "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
      ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
      ">>> Install complete. Run \"ollama\" from the command line.\n",
      "success                                                     \n",
      "Done!\n",
      "  Model\n",
      "    architecture        gptoss    \n",
      "    parameters          20.9B     \n",
      "    context length      131072    \n",
      "    embedding length    2880      \n",
      "    quantization        MXFP4     \n",
      "\n",
      "  Capabilities\n",
      "    completion    \n",
      "    tools         \n",
      "    thinking      \n",
      "\n",
      "  Parameters\n",
      "    temperature    1    \n",
      "\n",
      "  License\n",
      "    Apache License               \n",
      "    Version 2.0, January 2004    \n",
      "    ...                          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ollama のインストール・起動・モデルのダウンロード\n",
    "# 詳細は 01_connect_oss_llm.ipynb を参照\n",
    "import subprocess\n",
    "import time\n",
    "import ollama  # type: ignore\n",
    "\n",
    "!apt-get install -y -qq zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    [\"ollama\", \"serve\"],\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL,\n",
    ")\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "# AI エージェントにはツールコール対応モデルが必要。\n",
    "# NOTE: ollama pull のプログレスバーは Colab で文字化けするため、\n",
    "#       Python API 経由でステータスのみ表示する。\n",
    "\n",
    "model_name = \"gpt-oss:20b\"\n",
    "\n",
    "for progress in ollama.pull(model_name, stream=True):\n",
    "    status = progress.get(\"status\", \"\")\n",
    "    total = progress.get(\"total\") or 0\n",
    "    completed = progress.get(\"completed\") or 0\n",
    "    if total:\n",
    "        line = f\"{status}: {completed / total:.0%}\"\n",
    "    else:\n",
    "        line = status\n",
    "    print(f\"\\r{line:<60}\", end=\"\", flush=True)\n",
    "print(\"\\nDone!\")\n",
    "!ollama show {model_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ChatOllama で LLM に接続**\n",
    "- 詳細は [01_connect_oss_llm.ipynb](01_connect_oss_llm.ipynb) を参照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatOllama で LLM に接続する。\n",
    "from langchain_ollama import ChatOllama  # type: ignore\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gpt-oss:20b\",\n",
    "    num_ctx=16384,\n",
    "    num_predict=-1,\n",
    "    temperature=0.8,\n",
    "    top_k=40,\n",
    "    top_p=0.9,\n",
    "    repeat_penalty=1.1,\n",
    "    reasoning=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MCPサーバ（ddg-search）によるweb検索の実装**\n",
    "- langchain-mcp-adapters の MultiServerMCPClient を使用。\n",
    "- MCPサーバのツールが自動的に LangChain ツールに変換される（@tool の手動定義が不要）。\n",
    "- ReAct エージェントが bind_tools() で認識し、自律的にツールを呼び出せる形式になる。\n",
    "\n",
    "**MCPサーバ設定の補足**\n",
    "\n",
    "github に記載されているMCP接続の設定は以下\n",
    "> \"mcpServers\": {\"ddg-search\": {\"command\": \"uvx\", \"args\": [\"duckduckgo-mcp-server\"]}}\n",
    "\n",
    "今回は、pip install済なので、command=\"duckduckgo-mcp-server\" で直接起動。uvx経由ではないので、args=[] としてよい。\n",
    "\n",
    "**Colab の stderr 問題の回避（Colab 特有。通常の Python 環境では不要）**\n",
    "\n",
    "Colab の stderr は fileno() 未対応のため、MCP の stdio_client が失敗する。\n",
    "stdio_client の関数シグネチャ `errlog=sys.stderr` は**インポート時に評価が確定**するため、\n",
    "後から sys.stderr を差し替えても効果がない（Python のデフォルト引数の仕様）。\n",
    "そこで、langchain_mcp_adapters.sessions 内の stdio_client 参照自体を、\n",
    "errlog のデフォルトを /dev/null に変更したラッパー関数に差し替えて回避する。\n",
    "\n",
    "**httpx 0.28 互換性の回避（Colab 特有。通常の Python 環境では不要の可能性あり）**\n",
    "\n",
    "duckduckgo-mcp-server は httpx.TimeoutError を参照するが、依存先の httpx 0.28 で\n",
    "この属性が削除された（duckduckgo-mcp-server 側のバグ）。\n",
    "MCP サーバはサブプロセスで動作するため、ノートブック側のパッチが効かない。\n",
    "そこで、httpx をパッチしてからサーバを起動する Python ラッパー経由で起動する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AI エージェント用ツール ===\n",
      "  - search: \n",
      "    Search DuckDuckGo and return formatted results.\n",
      "\n",
      "    Args:\n",
      "        query: The search query string\n",
      "        max_results: Maximum number of results to return (default: 10)\n",
      "        ctx: MCP context for logging\n",
      "    \n",
      "  - fetch_content: \n",
      "    Fetch and parse content from a webpage URL.\n",
      "\n",
      "    Args:\n",
      "        url: The webpage URL to fetch content from\n",
      "        ctx: MCP context for logging\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# MCPサーバ（duckduckgo-mcp-server）に接続し、LangChainツールを自動取得\n",
    "# langchain-mcp-adapters が MCP ツールを LangChain 互換に自動変換するため、\n",
    "# @tool による手動ラップが不要\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "from langchain_mcp_adapters import sessions as _sessions  # type: ignore\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient  # type: ignore\n",
    "\n",
    "# --- Colab stderr 問題の回避パッチ（Colab 特有。通常環境では不要） ---\n",
    "# stdio_client(server, errlog=sys.stderr) のデフォルト値はインポート時に確定する。\n",
    "# Colab の stderr は fileno() 未対応のため、デフォルトのまま呼ぶと失敗する。\n",
    "# → errlog のデフォルトを /dev/null に差し替えたラッパーで上書きして回避する。\n",
    "# NOTE: _devnull はセッション中ずっと開いたままにする（閉じると書き込み先がなくなる）\n",
    "_devnull = open(os.devnull, \"w\")\n",
    "_original_stdio_client = _sessions.stdio_client\n",
    "\n",
    "\n",
    "@contextlib.asynccontextmanager\n",
    "async def _patched_stdio_client(server, errlog=_devnull):\n",
    "    async with _original_stdio_client(server, errlog=errlog) as result:\n",
    "        yield result\n",
    "\n",
    "\n",
    "_sessions.stdio_client = _patched_stdio_client\n",
    "\n",
    "\n",
    "# httpx 0.28 で削除された TimeoutError を復元してからサーバを起動するラッパー\n",
    "# duckduckgo-mcp-server はサブプロセスで動くため、ノートブック側のパッチが効かない\n",
    "_MCP_LAUNCHER = (\n",
    "    \"import httpx; \"\n",
    "    \"httpx.TimeoutError = getattr(httpx, 'TimeoutError', \"\n",
    "    \"type('TimeoutError', (Exception,), {})); \"\n",
    "    \"exec(open(__import__('shutil').which('duckduckgo-mcp-server')).read())\"\n",
    ")\n",
    "\n",
    "mcp_client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"ddg-search\": {\n",
    "            \"transport\": \"stdio\",\n",
    "            \"command\": sys.executable,  # python 本体を起動\n",
    "            \"args\": [\"-c\", _MCP_LAUNCHER],  # パッチ付きラッパー\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# MCP ツールを LangChain ツールとして自動取得\n",
    "tools = await mcp_client.get_tools()\n",
    "\n",
    "print(\"=== AI エージェント用ツール ===\")\n",
    "for t in tools:\n",
    "    print(f\"  - {t.name}: {t.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LangGraph による Workflow の実装**\n",
    "\n",
    "ReAct エージェント（03_01）は LLM が自律的にツールを呼び出すが、Workflow ではグラフ構造で処理フローを明示的に制御する。\n",
    "\n",
    "**Workflow の流れ**\n",
    "1. **task_planning**: ユーザの質問を受け取り、回答に必要な **サブタスク**（目的＋検索クエリ）を構造化して作成する。\n",
    "2. **web_search**: 各サブタスクの検索クエリを実行し、目的と紐付けた検索結果を蓄積する。\n",
    "3. **judge**: サブタスクの目的ごとに、検索結果が十分かを LLM が判断する。不足なら追加サブタスクを生成して web_search に戻る。\n",
    "4. **generate_answer**: 目的ごとに整理された検索結果をもとに、ユーザの質問に対する最終回答を生成する。\n",
    "\n",
    "**サブタスク構造**\n",
    "```json\n",
    "{\"purpose\": \"調査の目的\", \"queries\": [\"検索クエリ1\", \"検索クエリ2\"]}\n",
    "```\n",
    "- `purpose`: そのサブタスクで明らかにしたいこと（judge での判定基準になる）。\n",
    "- `queries`: 目的を達成するための具体的な検索クエリ。\n",
    "\n",
    "**ReAct との違い**\n",
    "- ReAct: LLM が思考→行動→観察のループを自律的に回す。ツール選択も LLM 任せ。\n",
    "- Workflow: 開発者がグラフで処理順序を定義し、各ノードの役割を明確に分離する。制御フローが予測可能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workflow の状態定義とツールの設定**\n",
    "\n",
    "MCP サーバ（ddg-search）は `search`（検索）と `fetch_content`（URL 本文取得）の2つのツールを提供するが、本 Workflow では `search` のみを使用する。\n",
    "\n",
    "`fetch_content` を追加しない理由:\n",
    "- `num_ctx=16384` の制約下では、Web ページ本文（数千〜数万トークン）を格納するとコンテキストがオーバーフローする。\n",
    "- 回避には fetch 後の LLM 要約が必要だが、スクレイピング, テキスト情報のクリーニング, RAG（検索拡張生成）などの実装が必要となり、notebook実装としては複雑すぎる。\n",
    "- DuckDuckGo のスニペットで回答品質が不足する場合に、限定的な導入（上位1件のみ fetch → 要約）を検討する。\n",
    "\n",
    "**LLM との入出力形式**\n",
    "\n",
    "各ノードは `messages` 引数で `[SystemMessage(...), HumanMessage(...)]` のリストを渡す統一形式を使用する。\n",
    "システムプロンプトは次のセルで定数として一括定義し、ノード関数はロジックに専念する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow の状態定義と共通インポート\n",
    "import json  # noqa: F811\n",
    "from typing import TypedDict\n",
    "from langchain_core.messages import HumanMessage, SystemMessage  # type: ignore\n",
    "from langgraph.graph import StateGraph, START, END  # type: ignore\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# --- グローバル設定 ---\n",
    "MAX_LOOP_COUNT = 2  # judge → web_search 再調査ループの上限回数（無限ループ防止）\n",
    "MAX_SEARCH_RESULTS = 5  # search ツールが返す検索結果の最大件数\n",
    "\n",
    "# --- 検索ツールの参照を取得 ---\n",
    "# next() の第2引数 None により、見つからない場合は StopIteration ではなく None を返す。\n",
    "# 直後の assert で None でないことを保証するため、以降 search_tool は BaseTool 型として扱える。\n",
    "search_tool = next((t for t in tools if t.name == \"search\"), None)\n",
    "assert search_tool is not None, \"search ツールが見つかりませんでした。\"\n",
    "\n",
    "\n",
    "# --- Workflow の状態 ---\n",
    "class WorkflowState(TypedDict):\n",
    "    question: str  # ユーザの質問\n",
    "    subtasks: list[dict]  # サブタスク [{\"purpose\": str, \"queries\": [str]}]\n",
    "    search_results: list[str]  # 目的と紐付けた検索結果\n",
    "    answer: str  # 最終回答\n",
    "    loop_count: int  # 再調査ループ回数（無限ループ防止）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**共通ユーティリティ: `extract_json_text`**\n",
    "\n",
    "LLM の出力から JSON 文字列を抽出するユーティリティ。\n",
    "\n",
    "`raw.strip()` で、LLM が出力したテキストから、文字列の両端にある空白文字（改行、スペース、タブなど）をすべて取り除く。「文字の間」にある空白には影響しない。\n",
    "\n",
    "さらに、LLM の出力で起こりがちな、以下の3ケースに対応する。\n",
    "1. **コードブロック**: ` ```json ... ``` ` — 正規表現でコードブロック内の中身を抽出する。\n",
    "2. **前後にテキスト付き**: `\"以下がサブタスクです: [{...}]\"` — 最初の `[` or `{` から、対応する最後の `]` or `}` までを切り出す。\n",
    "3. **JSON のみ**: `[{...}]` or `{...}` — そのままパース可能。\n",
    "\n",
    "抽出後は `json.loads()` で Python のリスト型/辞書型に変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共通ユーティリティ: LLM 出力から JSON 文字列を抽出する\n",
    "import json  # noqa: F811\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_json_text(raw: str) -> str:\n",
    "    \"\"\"LLM の出力から JSON 文字列を抽出する。\n",
    "\n",
    "    以下のケースに対応:\n",
    "    1. コードブロック: ```json ... ``` or ``` ... ```\n",
    "    2. 前後にテキスト付き: \"以下がサブタスクです: [{...}]\"\n",
    "    3. JSON のみ: [{...}] or {...}\n",
    "    \"\"\"\n",
    "    text = raw.strip()\n",
    "\n",
    "    # ケース 1: コードブロックの除去\n",
    "    # 複数のコードブロックがある場合も考慮し、単純な split ではなく正規表現で中身を抽出\n",
    "    code_block_match = re.search(r\"```(?:json)?\\s*(.*?)```\", text, re.DOTALL)\n",
    "    if code_block_match:\n",
    "        text = code_block_match.group(1).strip()\n",
    "\n",
    "    # コードブロック内が正常な JSON ならそのまま返す\n",
    "    try:\n",
    "        json.loads(text)\n",
    "        return text\n",
    "    except json.JSONDecodeError:\n",
    "        pass  # パースできなければ、テキスト全体からの抽出（ケース 2, 3）へ進む\n",
    "\n",
    "    # ケース 2, 3: テキスト混じりの場合\n",
    "    # 「最初の { か [」を探し、対応する「最後の } か ]」を探して切り出す\n",
    "    match_start = re.search(r\"[\\{\\[]\", text)\n",
    "    if not match_start:\n",
    "        return text  # JSON の開始記号がない\n",
    "\n",
    "    first_brace_index = match_start.start()\n",
    "    start_char = text[first_brace_index]\n",
    "    end_char = \"]\" if start_char == \"[\" else \"}\"\n",
    "\n",
    "    last_brace_index = text.rfind(end_char)\n",
    "    if last_brace_index > first_brace_index:\n",
    "        return text[first_brace_index : last_brace_index + 1]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**各ノードのシステムプロンプト定義**\n",
    "\n",
    "各ノード（task_planning / judge / generate_answer）が LLM に渡すシステムプロンプトを一箇所に集約する。\n",
    "- プロンプトの確認・調整が容易になる。\n",
    "- ノード関数のロジックとプロンプトの関心を分離する。\n",
    "\n",
    "**参考：JSON データ形式**\n",
    "- `key` : `value` の組から構成されるデータ\n",
    "- `{ }` で、`\"purpose\"` と `\"queries\"` で 1セットのデータ（辞書）として定義\n",
    "- `[ ]` で、辞書：`{ }` のリストとして定義\n",
    "- ... は、`{ }` の部分の繰り返しであることを意味する\n",
    "- JSON の仕様では、true/false。Python の仕様では、True/False。`SYSTEM_PROMPT_JUDGE` の `\"sufficient\"` の判定は、JSON の仕様で出力するので、true/falseで記述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各ノードのシステムプロンプト定義\n",
    "# ノード関数のロジックとプロンプトの関心を分離するため、一箇所に集約する。\n",
    "SYSTEM_PROMPT_TASK_PLANNING = \"\"\"\n",
    "あなたはリサーチプランナーです。\n",
    "ユーザの質問に回答するために必要な調査サブタスクを作成してください。\n",
    "\n",
    "出力は以下の JSON 配列のみとし、他のテキストは一切含めないでください。\n",
    "サブタスクは最大3個までとしてください。\n",
    "\n",
    "出力形式:\n",
    "[\n",
    "  {\"purpose\": \"このサブタスクで明らかにしたいこと\",\n",
    "   \"queries\": [\"検索クエリ1\", \"検索クエリ2\"]},\n",
    "  ...\n",
    "]\n",
    "\n",
    "purpose は判定ステップで「この目的に十分な情報が得られたか」を評価する基準になります。\n",
    "具体的かつ明確に書いてください。\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_JUDGE = \"\"\"\n",
    "あなたはリサーチの品質を判定する審査員です。\n",
    "ユーザの質問と検索結果を見て、回答に十分な情報があるか判断してください。\n",
    "検索結果には【目的: ...】タグが付いています。\n",
    "各目的について十分な情報が得られているかを確認してください。\n",
    "\n",
    "十分な場合:\n",
    "{\"sufficient\": true, \"reason\": \"判断理由を日本語で1文で\"}\n",
    "\n",
    "不足の場合（不足している目的について追加サブタスクを生成）:\n",
    "{\"sufficient\": false, \"reason\": \"何が不足しているかを日本語で1文で\",\n",
    " \"additional_subtasks\": [\n",
    "    {\"purpose\": \"追加で明らかにしたいこと\",\n",
    "     \"queries\": [\"追加クエリ1\"]}\n",
    "  ]\n",
    "}\n",
    "\n",
    "JSON のみ出力し、他のテキストは含めないでください。\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT_GENERATE_ANSWER = \"\"\"\n",
    "あなたはリサーチ結果をもとに回答するAIアシスタントです。\n",
    "検索結果を参考に、ユーザの質問に日本語で丁寧に回答してください。\n",
    "回答の最後に、以下の形式で結論をまとめてください。\n",
    "\n",
    "# 結論\n",
    "- ユーザの質問: （質問内容）\n",
    "- 回答: （簡潔な回答）\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ノード 1: task_planning（タスク分割）**\n",
    "- ユーザの質問を分析し、回答に必要な **サブタスク**（目的＋検索クエリ）を構造化して作成する。\n",
    "- 各サブタスクは `purpose`（何を明らかにしたいか）と `queries`（検索クエリ群）で構成される。\n",
    "- LLM に JSON 配列のみを出力させ、パースして `subtasks` に格納する。\n",
    "\n",
    "**参考：JSON 配列のパース**\n",
    "- `extract_json_text` で実施。**共通ユーティリティ**を参照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ノード 1: task_planning（タスク分割）\n",
    "async def task_planning(state: WorkflowState) -> dict:\n",
    "    \"\"\"ユーザの質問を分析し、サブタスク（目的＋検索クエリ）を作成する。\"\"\"\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    response = await llm.ainvoke(\n",
    "        [\n",
    "            SystemMessage(content=SYSTEM_PROMPT_TASK_PLANNING),\n",
    "            HumanMessage(content=question),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # LLM の出力から JSON 配列を抽出\n",
    "    text = extract_json_text(response.content)\n",
    "\n",
    "    try:\n",
    "        subtasks = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        # パース失敗時は質問そのものを検索クエリにして続行する\n",
    "        print(f\"[task_planning] JSON パース失敗 → フォールバック: {text[:100]}\")\n",
    "        subtasks = [{\"purpose\": \"基本調査\", \"queries\": [question]}]\n",
    "\n",
    "    print(f\"[task_planning] サブタスク数: {len(subtasks)}\")\n",
    "    for i, st in enumerate(subtasks):\n",
    "        print(f\"  {i + 1}. 目的: {st['purpose']}\")\n",
    "        print(f\"     クエリ: {st['queries']}\")\n",
    "    return {\"subtasks\": subtasks, \"search_results\": [], \"loop_count\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[task_planning] サブタスク数: 2\n",
      "  1. 目的: 日本政府が公表した2025年の総人口推計値を確認する\n",
      "     クエリ: ['2025 年 日本 総人口 推計 日本統計局', '内閣府 2025 年人口見通し 日本']\n",
      "  2. 目的: 民間調査機関や国際機関の報告書で2025年の日本人口予測を比較検証する\n",
      "     クエリ: ['2025 年 日本 人口予測 OECD', '2025 日本人口 推計 民間調査']\n",
      "\n",
      "subtasks: [\n",
      "  {\n",
      "    \"purpose\": \"日本政府が公表した2025年の総人口推計値を確認する\",\n",
      "    \"queries\": [\n",
      "      \"2025 年 日本 総人口 推計 日本統計局\",\n",
      "      \"内閣府 2025 年人口見通し 日本\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"purpose\": \"民間調査機関や国際機関の報告書で2025年の日本人口予測を比較検証する\",\n",
      "    \"queries\": [\n",
      "      \"2025 年 日本 人口予測 OECD\",\n",
      "      \"2025 日本人口 推計 民間調査\"\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# task_planning の単体確認\n",
    "# ensure_ascii=False の指定をしないと日本語が文字化けするので注意\n",
    "_test_state = {\"question\": \"2025年の日本の総人口は何人ですか？\"}\n",
    "_result = await task_planning(_test_state)\n",
    "\n",
    "print(f\"\\nsubtasks: {json.dumps(_result['subtasks'], ensure_ascii=False, indent=2)}\")\n",
    "assert isinstance(_result[\"subtasks\"], list), \"subtasks がリストではありません\"\n",
    "assert len(_result[\"subtasks\"]) > 0, \"サブタスクが空です\"\n",
    "for st in _result[\"subtasks\"]:\n",
    "    assert \"purpose\" in st, f\"purpose キーがありません: {st}\"\n",
    "    assert \"queries\" in st, f\"queries キーがありません: {st}\"\n",
    "    assert isinstance(st[\"queries\"], list), f\"queries がリストではありません: {st}\"\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ノード 2: web_search（Web 検索）**\n",
    "\n",
    "`subtasks` 内の各サブタスクについて、`queries` を順番に MCP の `search` ツールで実行する。\n",
    "- `list(state.get(\"search_results\") or [])` で、「初回実行時は空リスト、2回目（ループ時）は前回の結果を引き継ぐ」として動作させる。list(...) で囲うことにより、元のデータをコピーして壊さないようにしている。\n",
    "- 検索結果はサブタスクの `purpose`（目的）と紐付けて `search_results` に蓄積する。\n",
    "> `results.append` で、目的: {purpose}, クエリ: {query}, {result} のように構造化したデータとして保存。\n",
    "- 実行済みのサブタスクは `subtasks` からクリアされる。\n",
    "> `\"subtasks\": []` でサブタスクを空にしている。\n",
    "- 検索結果が空（DuckDuckGo のbot検出等）の場合は蓄積せずスキップし、judge が不要な再調査を行うのを防ぐ。\n",
    "\n",
    "**逐次実行 + 待機を採用する理由**\n",
    "- DuckDuckGo は同一IPからの短時間の大量リクエストをbot検出する。\n",
    "- `asyncio.gather` 等で並列化するとバースト的なリクエストになり、全クエリがブロックされるリスクが高い。\n",
    "- 逐次実行かつクエリ間に `_SEARCH_INTERVAL_SEC`（1秒）の待機を入れることで、bot検出を回避する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ノード 2: web_search（Web 検索）\n",
    "import asyncio\n",
    "\n",
    "# 検索結果が空かどうかを判定するキーワード\n",
    "_NO_RESULT_KEYWORDS = [\"No results were found\", \"no matching results\"]\n",
    "\n",
    "# 検索クエリ間の待機時間（秒）。DuckDuckGo のbot検出を回避するため。\n",
    "_SEARCH_INTERVAL_SEC = 1.0\n",
    "\n",
    "\n",
    "async def web_search(state: WorkflowState) -> dict:\n",
    "    \"\"\"各サブタスクの検索クエリを逐次実行し、目的と紐付けて結果を蓄積する。\"\"\"\n",
    "    subtasks = state[\"subtasks\"]\n",
    "    results = list(state.get(\"search_results\") or [])\n",
    "    is_first_query = True\n",
    "\n",
    "    for st in subtasks:\n",
    "        purpose = st[\"purpose\"]\n",
    "        print(f\"[web_search] 目的: {purpose}\")\n",
    "        for query in st[\"queries\"]:\n",
    "            # 2回目以降のクエリは待機してからbot検出を回避\n",
    "            if not is_first_query:\n",
    "                await asyncio.sleep(_SEARCH_INTERVAL_SEC)\n",
    "            is_first_query = False\n",
    "\n",
    "            print(f\"  検索中: {query}\")\n",
    "            try:\n",
    "                result = await search_tool.ainvoke(\n",
    "                    {\"query\": query, \"max_results\": MAX_SEARCH_RESULTS}\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"  [ERROR] クエリ失敗: {query} → {e}\")\n",
    "                continue\n",
    "            # 検索結果が空（bot検出等）の場合はスキップ\n",
    "            result_str = str(result)\n",
    "            if any(kw in result_str for kw in _NO_RESULT_KEYWORDS):\n",
    "                print(f\"  [SKIP] 検索結果なし: {query}\")\n",
    "                continue\n",
    "            results.append(f\"【目的: {purpose}】\\n【クエリ: {query}】\\n{result}\")\n",
    "\n",
    "    return {\"search_results\": results, \"subtasks\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[web_search] 目的: 2025年の日本の総人口の最新の公式発表値を確認する\n",
      "  検索中: 2025年 日本 総人口\n",
      "  検索中: 総務省 2025年 人口推計\n",
      "\n",
      "検索結果数: 2\n",
      "結果1（先頭200文字）: 【目的: 2025年の日本の総人口の最新の公式発表値を確認する】\n",
      "【クエリ: 2025年 日本 総人口】\n",
      "[{'type': 'text', 'text': 'Found 5 search results:\\n\\n1. 人口推計（2025年（令和7年）8月確定値、2026年（令和8年）1月概算値） （2026年1月20日公表）\\n   URL: https://www.stat.go.jp/dat\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# web_search の単体確認\n",
    "_test_state = {\n",
    "    \"question\": \"2025年の日本の総人口は何人ですか？\",\n",
    "    \"subtasks\": [\n",
    "        {\n",
    "            \"purpose\": \"2025年の日本の総人口の最新の公式発表値を確認する\",\n",
    "            \"queries\": [\"2025年 日本 総人口\", \"総務省 2025年 人口推計\"],\n",
    "        }\n",
    "    ],\n",
    "    \"search_results\": [],\n",
    "}\n",
    "_result = await web_search(_test_state)\n",
    "\n",
    "print(f\"\\n検索結果数: {len(_result['search_results'])}\")\n",
    "# DuckDuckGo のbot検出で空結果がスキップされる場合があるため、\n",
    "# 結果数は 0〜2 の範囲で正常とする\n",
    "assert len(_result[\"search_results\"]) <= 2, (\n",
    "    f\"クエリ2本に対して結果が {len(_result['search_results'])} 件は多すぎます\"\n",
    ")\n",
    "if _result[\"search_results\"]:\n",
    "    print(f\"結果1（先頭200文字）: {_result['search_results'][0][:200]}\")\n",
    "    assert \"【目的:\" in _result[\"search_results\"][0], \"目的タグが付いていません\"\n",
    "else:\n",
    "    print(\"[INFO] 全クエリが空結果のためスキップされました（bot検出の可能性）\")\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ノード 3: judge（判定）+ ルーター**\n",
    "- サブタスクの**目的ごと**に、検索結果が十分かを LLM が判断する。\n",
    "- 全ての目的が達成されていれば `generate_answer` へ進む。\n",
    "- 不足する目的があれば、追加サブタスク（目的＋クエリ）を生成して `web_search` に戻る。\n",
    "- 無限ループ防止のため、再調査は最大2回まで。\n",
    "- `should_continue_search` ルーターが judge の出力（`subtasks` の有無）を見て次のノードを決定する。\n",
    "\n",
    "**参考：JSON 配列のパース**\n",
    "- `extract_json_text` で実施。**共通ユーティリティ**を参照。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ノード 3: judge（判定）\n",
    "async def judge(state: WorkflowState) -> dict:\n",
    "    \"\"\"サブタスクの目的ごとに検索結果が十分かを判断し、不足なら追加サブタスクを生成する。\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    results = state[\"search_results\"]\n",
    "    loop_count = state.get(\"loop_count\", 0)  # 値が空の場合に 0 をセットする\n",
    "\n",
    "    # 無限ループ防止: MAX_LOOP_COUNT 回まで再調査\n",
    "    if loop_count >= MAX_LOOP_COUNT:\n",
    "        print(\"[judge] ループ上限に到達 → 回答作成へ\")\n",
    "        return {\"subtasks\": [], \"loop_count\": loop_count}\n",
    "\n",
    "    # LLM テキストを渡すために、検索結果を 1つの文章に結合（区切り：\\n\\n）\n",
    "    results_text = \"\\n\\n\".join(results)\n",
    "\n",
    "    response = await llm.ainvoke(\n",
    "        [\n",
    "            SystemMessage(content=SYSTEM_PROMPT_JUDGE),\n",
    "            HumanMessage(content=f\"質問: {question}\\n\\n検索結果:\\n{results_text}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    text = extract_json_text(response.content)\n",
    "\n",
    "    try:\n",
    "        judgment = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        # パース失敗時は十分と見なして先に進む\n",
    "        print(f\"[judge] JSON パース失敗 → 回答作成へ: {text[:100]}\")\n",
    "        return {\"subtasks\": [], \"loop_count\": loop_count + 1}\n",
    "\n",
    "    reason = judgment.get(\"reason\", \"\")  # 値が空の場合に \"\"（空）をセットする\n",
    "\n",
    "    if judgment.get(\"sufficient\", True):\n",
    "        print(f\"[judge] 情報十分 → 回答作成へ（理由: {reason}）\")\n",
    "        return {\"subtasks\": [], \"loop_count\": loop_count + 1}\n",
    "    else:\n",
    "        additional = judgment.get(\"additional_subtasks\", [])\n",
    "        print(f\"[judge] 情報不足（理由: {reason}）→ 追加サブタスク:\")\n",
    "        for i, st in enumerate(additional):\n",
    "            print(f\"  {i + 1}. 目的: {st.get('purpose', '?')}\")\n",
    "            print(f\"     クエリ: {st.get('queries', [])}\")\n",
    "        return {\"subtasks\": additional, \"loop_count\": loop_count + 1}\n",
    "\n",
    "\n",
    "# ルーター: judge の結果で分岐\n",
    "def should_continue_search(state: WorkflowState) -> str:\n",
    "    \"\"\"追加サブタスクがあれば web_search に戻り、なければ回答生成へ。\"\"\"\n",
    "    if state.get(\"subtasks\"):\n",
    "        return \"web_search\"\n",
    "    return \"generate_answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[judge] 情報十分 → 回答作成へ（理由: 検索結果に公式発表値が含まれているため質問に十分に回答できる）\n",
      "subtasks: []\n",
      "loop_count: 1\n",
      "ルーター判定: generate_answer\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "# judge + ルーターの単体確認\n",
    "_test_state = {\n",
    "    \"question\": \"2025年の日本の総人口は何人ですか？\",\n",
    "    \"subtasks\": [],\n",
    "    \"search_results\": [\n",
    "        \"【目的: 2025年の日本の総人口の最新の公式発表値を確認する】\\n\"\n",
    "        \"【クエリ: 2025年 日本 総人口】\\n\"\n",
    "        \"総務省発表: 2025年1月1日時点の住民基本台帳に基づく総人口は1億2433万690人\"\n",
    "    ],\n",
    "    \"loop_count\": 0,\n",
    "}\n",
    "_result = await judge(_test_state)\n",
    "\n",
    "print(f\"subtasks: {_result['subtasks']}\")\n",
    "print(f\"loop_count: {_result['loop_count']}\")\n",
    "\n",
    "# ルーターの確認\n",
    "_next = should_continue_search({**_test_state, **_result})\n",
    "print(f\"ルーター判定: {_next}\")\n",
    "assert _next in (\"web_search\", \"generate_answer\"), f\"不正なルーター出力: {_next}\"\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ノード 4: generate_answer（回答生成）**\n",
    "- 目的ごとに整理された検索結果をもとに、ユーザの質問に対する最終回答を生成する。\n",
    "- 検索結果に含まれる【目的: ...】タグにより、LLM が情報の文脈を把握しやすくなる。\n",
    "- 回答の最後に「結論」セクションを付ける。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ノード 4: generate_answer（回答生成）\n",
    "async def generate_answer(state: WorkflowState) -> dict:\n",
    "    \"\"\"蓄積した検索結果をもとに最終回答を生成する。\"\"\"\n",
    "    question = state[\"question\"]\n",
    "    results_text = \"\\n\\n\".join(state[\"search_results\"])\n",
    "\n",
    "    response = await llm.ainvoke(\n",
    "        [\n",
    "            SystemMessage(content=SYSTEM_PROMPT_GENERATE_ANSWER),\n",
    "            HumanMessage(content=f\"質問: {question}\\n\\n検索結果:\\n{results_text}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    answer = response.content or \"\"\n",
    "\n",
    "    # content が空の場合、レスポンスの他の属性を確認する\n",
    "    if not answer:\n",
    "        print(\"[generate_answer] WARNING: response.content が空です\")\n",
    "        print(f\"  response type: {type(response)}\")\n",
    "        print(f\"  response keys: {list(response.__dict__.keys())}\")\n",
    "        print(f\"  response repr: {repr(response)[:500]}\")\n",
    "        # additional_kwargs に内容がある場合のフォールバック\n",
    "        additional = getattr(response, \"additional_kwargs\", {})\n",
    "        if additional:\n",
    "            print(f\"  additional_kwargs: {repr(additional)[:300]}\")\n",
    "\n",
    "    print(\"[generate_answer] 回答生成完了\")\n",
    "    return {\"answer\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[generate_answer] 回答生成完了\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "2025年1月1日時点の総務省の住民基本台帳に基づく公式発表によると、全国総人口は **1億2,433万6,900人** です。前年からは約55万人減少しています。\n",
       "\n",
       "# 結論\n",
       "- ユーザの質問: 2025年の日本の総人口は何人ですか？\n",
       "- 回答: 1億2,433万6,900人です。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate_answer の単体確認\n",
    "from IPython.display import Markdown\n",
    "\n",
    "_test_state = {\n",
    "    \"question\": \"2025年の日本の総人口は何人ですか？\",\n",
    "    \"search_results\": [\n",
    "        \"【目的: 2025年の日本の総人口の最新の公式発表値を確認する】\\n\"\n",
    "        \"【クエリ: 2025年 日本 総人口】\\n\"\n",
    "        \"総務省発表: 2025年1月1日時点の住民基本台帳に基づく総人口は1億2433万690人。\"\n",
    "        \"前年より55万4485人(0.44%)減少。日本人は1億2065万3227人で0.75%減少。\"\n",
    "    ],\n",
    "}\n",
    "_result = await generate_answer(_test_state)\n",
    "\n",
    "assert \"answer\" in _result, \"answer キーが存在しません\"\n",
    "assert len(_result[\"answer\"]) > 0, \"回答が空です\"\n",
    "display(Markdown(_result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workflow グラフの構築**\n",
    "- 上記4つのノードを StateGraph に登録し、エッジで接続する。\n",
    "- `judge` ノードの後に条件分岐（`should_continue_search`）を設定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Workflow グラフの構築とコンパイル\n",
    "workflow = StateGraph(WorkflowState)\n",
    "\n",
    "# ノードの登録\n",
    "workflow.add_node(\"task_planning\", task_planning)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"judge\", judge)\n",
    "workflow.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "# エッジの定義\n",
    "workflow.add_edge(START, \"task_planning\")\n",
    "workflow.add_edge(\"task_planning\", \"web_search\")\n",
    "workflow.add_edge(\"web_search\", \"judge\")\n",
    "\n",
    "# 条件分岐: judge → web_search（再調査） or generate_answer（回答生成）\n",
    "workflow.add_conditional_edges(\n",
    "    \"judge\",\n",
    "    should_continue_search,\n",
    "    {\n",
    "        \"web_search\": \"web_search\",\n",
    "        \"generate_answer\": \"generate_answer\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "\n",
    "# コンパイル\n",
    "app = workflow.compile()\n",
    "\n",
    "# グラフの可視化\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**動作確認**\n",
    "- Workflow エージェントに質問を投げ、タスク分割 → Web 検索 → 判定 → 回答生成の流れを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[task_planning] サブタスク数: 3\n",
      "  1. 目的: Find the most recent official estimate of Japan's total population for the year 2025, preferably from the Japanese government or an authoritative international organization.\n",
      "     クエリ: ['Japan population estimate 2025', '国勢調査 2025 人口推計', 'Japan 2025 population forecast official']\n",
      "  2. 目的: Verify the 2025 population figure by comparing it with independent sources such as the United Nations, World Bank, or OECD to ensure consistency and accuracy.\n",
      "     クエリ: ['United Nations population estimates Japan 2025', 'World Bank Japan population 2025', 'OECD Japan population 2025']\n",
      "  3. 目的: Cross‑check the 2025 estimate with recent news articles or academic papers that discuss Japan's demographic trends to confirm that the figure is up to date and reflects any recent revisions.\n",
      "     クエリ: ['Japan 2025 population trend article', '2025 Japanese population projection news', 'Japan demographic forecast 2025 academic paper']\n",
      "[web_search] 目的: Find the most recent official estimate of Japan's total population for the year 2025, preferably from the Japanese government or an authoritative international organization.\n",
      "  検索中: Japan population estimate 2025\n",
      "  検索中: 国勢調査 2025 人口推計\n",
      "  検索中: Japan 2025 population forecast official\n",
      "  [SKIP] 検索結果なし: Japan 2025 population forecast official\n",
      "[web_search] 目的: Verify the 2025 population figure by comparing it with independent sources such as the United Nations, World Bank, or OECD to ensure consistency and accuracy.\n",
      "  検索中: United Nations population estimates Japan 2025\n",
      "  [SKIP] 検索結果なし: United Nations population estimates Japan 2025\n",
      "  検索中: World Bank Japan population 2025\n",
      "  [SKIP] 検索結果なし: World Bank Japan population 2025\n",
      "  検索中: OECD Japan population 2025\n",
      "  [SKIP] 検索結果なし: OECD Japan population 2025\n",
      "[web_search] 目的: Cross‑check the 2025 estimate with recent news articles or academic papers that discuss Japan's demographic trends to confirm that the figure is up to date and reflects any recent revisions.\n",
      "  検索中: Japan 2025 population trend article\n",
      "  [SKIP] 検索結果なし: Japan 2025 population trend article\n",
      "  検索中: 2025 Japanese population projection news\n",
      "  [SKIP] 検索結果なし: 2025 Japanese population projection news\n",
      "  検索中: Japan demographic forecast 2025 academic paper\n",
      "  [SKIP] 検索結果なし: Japan demographic forecast 2025 academic paper\n",
      "[judge] 情報十分 → 回答作成へ（理由: 国勢調査による公式推計（1億2326万8千人）が得られたため、2025年の日本の総人口を回答できる十分な情報がある）\n",
      "[generate_answer] 回答生成完了\n",
      "\n",
      "--- 以下は HTML による全文ログ（トランケート回避） ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='white-space:pre-wrap'>[task_planning] サブタスク数: 3\n",
       "  1. 目的: Find the most recent official estimate of Japan's total population for the year 2025, preferably from the Japanese government or an authoritative international organization.\n",
       "     クエリ: ['Japan population estimate 2025', '国勢調査 2025 人口推計', 'Japan 2025 population forecast official']\n",
       "  2. 目的: Verify the 2025 population figure by comparing it with independent sources such as the United Nations, World Bank, or OECD to ensure consistency and accuracy.\n",
       "     クエリ: ['United Nations population estimates Japan 2025', 'World Bank Japan population 2025', 'OECD Japan population 2025']\n",
       "  3. 目的: Cross‑check the 2025 estimate with recent news articles or academic papers that discuss Japan's demographic trends to confirm that the figure is up to date and reflects any recent revisions.\n",
       "     クエリ: ['Japan 2025 population trend article', '2025 Japanese population projection news', 'Japan demographic forecast 2025 academic paper']\n",
       "[web_search] 目的: Find the most recent official estimate of Japan's total population for the year 2025, preferably from the Japanese government or an authoritative international organization.\n",
       "  検索中: Japan population estimate 2025\n",
       "  検索中: 国勢調査 2025 人口推計\n",
       "  検索中: Japan 2025 population forecast official\n",
       "  [SKIP] 検索結果なし: Japan 2025 population forecast official\n",
       "[web_search] 目的: Verify the 2025 population figure by comparing it with independent sources such as the United Nations, World Bank, or OECD to ensure consistency and accuracy.\n",
       "  検索中: United Nations population estimates Japan 2025\n",
       "  [SKIP] 検索結果なし: United Nations population estimates Japan 2025\n",
       "  検索中: World Bank Japan population 2025\n",
       "  [SKIP] 検索結果なし: World Bank Japan population 2025\n",
       "  検索中: OECD Japan population 2025\n",
       "  [SKIP] 検索結果なし: OECD Japan population 2025\n",
       "[web_search] 目的: Cross‑check the 2025 estimate with recent news articles or academic papers that discuss Japan's demographic trends to confirm that the figure is up to date and reflects any recent revisions.\n",
       "  検索中: Japan 2025 population trend article\n",
       "  [SKIP] 検索結果なし: Japan 2025 population trend article\n",
       "  検索中: 2025 Japanese population projection news\n",
       "  [SKIP] 検索結果なし: 2025 Japanese population projection news\n",
       "  検索中: Japan demographic forecast 2025 academic paper\n",
       "  [SKIP] 検索結果なし: Japan demographic forecast 2025 academic paper\n",
       "[judge] 情報十分 → 回答作成へ（理由: 国勢調査による公式推計（1億2326万8千人）が得られたため、2025年の日本の総人口を回答できる十分な情報がある）\n",
       "[generate_answer] 回答生成完了\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Workflow エージェントの実行結果 ===\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "2025年の日本の総人口は、**約1億2326万8千人**（123,268,000人）です。  \n",
       "これは、総務省（国勢調査）による2025年8月1日現在の確定値で、政府統計の公式推計値として最も信頼性が高いデータです。  \n",
       "\n",
       "# 結論  \n",
       "- ユーザの質問: 2025年の日本の総人口は何人ですか？  \n",
       "- 回答: 2025年8月1日現在の総務省の確定値で、約1億2326万8千人です。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Workflow エージェントの動作確認\n",
    "# MCPツールは非同期専用のため ainvoke を使用する\n",
    "import io\n",
    "import sys\n",
    "from IPython.display import Markdown, HTML, display\n",
    "\n",
    "# 中間ログをキャプチャしつつ、リアルタイムでもセルに出力する\n",
    "log_buffer = io.StringIO()\n",
    "\n",
    "\n",
    "class TeeStream:\n",
    "    \"\"\"stdout への出力を画面表示しつつバッファにも記録する。\"\"\"\n",
    "\n",
    "    def __init__(self, original, buffer):\n",
    "        self.original = original\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def write(self, text):\n",
    "        self.original.write(text)\n",
    "        self.buffer.write(text)\n",
    "\n",
    "    def flush(self):\n",
    "        self.original.flush()\n",
    "\n",
    "\n",
    "_original_stdout = sys.stdout\n",
    "sys.stdout = TeeStream(_original_stdout, log_buffer)\n",
    "try:\n",
    "    result = await app.ainvoke({\"question\": \"2025年の日本の総人口は何人ですか？\"})\n",
    "finally:\n",
    "    sys.stdout = _original_stdout\n",
    "\n",
    "# 中間ログを HTML で全文表示（Colab のセル出力トランケートを回避）\n",
    "log_text = log_buffer.getvalue()\n",
    "print(\"\\n--- 以下は HTML による全文ログ（トランケート回避） ---\")\n",
    "display(HTML(f\"<pre style='white-space:pre-wrap'>{log_text}</pre>\"))\n",
    "\n",
    "# 最終回答の表示\n",
    "print(\"=== Workflow エージェントの実行結果 ===\\n\")\n",
    "answer = result.get(\"answer\", \"\")\n",
    "if answer:\n",
    "    display(Markdown(answer))\n",
    "else:\n",
    "    print(\"[WARNING] 回答が空です。result keys:\", list(result.keys()))\n",
    "    print(\"search_results 件数:\", len(result.get(\"search_results\", [])))\n",
    "    print(\"loop_count:\", result.get(\"loop_count\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
