{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08 Agentic RAG Main\u30eb\u30fc\u30c1\u30f3\uff08Clean Architecture\uff09\n",
    "\n",
    "**`src/` \u914d\u4e0b\u306e Clean Architecture \u30e2\u30b8\u30e5\u30fc\u30eb\u3092 `DIContainer` \u7d4c\u7531\u3067\u4f7f\u7528\u3059\u308b Main \u30eb\u30fc\u30c1\u30f3\u3002**\n",
    "\n",
    "gpt-oss:20b \u3092\u4f7f\u7528\u3059\u308b\u69cb\u6210\u306e\u305f\u3081\u3001**Colab GPU \u306f L4 \u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3002**\n",
    "\n",
    "#### \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\n",
    "- **Domain \u5c64**: \u30c9\u30e1\u30a4\u30f3\u30e2\u30c7\u30eb\u3001Port\uff08Protocol\uff09\u3001`WorkflowConfig`\n",
    "- **Use Cases \u5c64**: `AgentWorkflow`\uff08LangGraph\uff09\u3001`DataIngestion`\u3001\u5404\u30ce\u30fc\u30c9\n",
    "- **Interface Adapters \u5c64**: `OllamaAdapter`\u3001`ChromaDBAdapter`\u3001`RerankerAdapter`\u3001`PDFLoaderAdapter`\u3001`GradioHandler`\n",
    "- **Infrastructure \u5c64**: `DIContainer`\uff08\u4f9d\u5b58\u6027\u306e\u7d44\u307f\u7acb\u3066\u30fb\u6ce8\u5165\uff09\n",
    "\n",
    "#### \u30ef\u30fc\u30af\u30d5\u30ed\u30fc\n",
    "1. **task_planning**: \u30e6\u30fc\u30b6\u306e\u8cea\u554f\u3092\u5206\u6790\u3057\u3001\u30b5\u30d6\u30bf\u30b9\u30af\uff08\u76ee\u7684\uff0b\u691c\u7d22\u30af\u30a8\u30ea\uff09\u3092\u4f5c\u6210\n",
    "2. **doc_search**: \u30cf\u30a4\u30d6\u30ea\u30c3\u30c9\u691c\u7d22\uff08BM25 + \u30d9\u30af\u30c8\u30eb\uff09+ Reranker\n",
    "3. **summarize**: \u691c\u7d22\u7d50\u679c\u3092\u8981\u7d04\uff08Judge \u306e\u5165\u529b\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u524a\u6e1b\uff09\n",
    "4. **judge**: \u60c5\u5831\u306e\u5341\u5206\u6027\u3092\u5224\u5b9a\u3002\u4e0d\u8db3\u306a\u3089 doc_search \u306b\u623b\u308b\n",
    "5. **generate_answer**: \u6700\u7d42\u56de\u7b54\u3092\u30b9\u30c8\u30ea\u30fc\u30df\u30f3\u30b0\u751f\u6210"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colab \u306b\u5fc5\u8981\u306a\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002\n",
    "# NOTE: Colab \u3067\u306f uv \u3067\u306f\u306a\u304f pip \u3092\u4f7f\u3046\u3002\n",
    "#       uv \u306f\u4f9d\u5b58\u89e3\u6c7a\u306e\u904e\u7a0b\u3067 numpy \u7b49\u3092\u30a2\u30c3\u30d7\u30b0\u30ec\u30fc\u30c9\u3057\u3001\n",
    "#       \u30d7\u30ea\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6e08\u307f\u306e scipy \u7b49\u3092\u58ca\u3059\u305f\u3081\u3002\n",
    "\n",
    "# fmt: off\n",
    "pkgs = [\n",
    "    \"ollama\", \"langchain-ollama\",\n",
    "    \"langchain>=1.2.8\", \"langchain-core>=1.2.8\", \"langgraph>=1.0.7\",\n",
    "    \"markitdown[all]\", \"chromadb\", \"rank-bm25\",\n",
    "    \"spacy\", \"sentence-transformers\",\n",
    "    \"pydantic>=2.12\", \"pydantic-settings>=2.13\",\n",
    "    \"gradio>=6.0\",\n",
    "]\n",
    "# fmt: on\n",
    "\n",
    "%pip install -U -q {\" \".join(pkgs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy \u65e5\u672c\u8a9e\u30e2\u30c7\u30eb\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n",
    "!python -m spacy download ja_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Google Colab \u306b Ollama \u3092\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7**\n",
    "- \u8a73\u7d30\u306f [01_connect_oss_llm.ipynb](01_connect_oss_llm.ipynb) \u3092\u53c2\u7167\u3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u30fb\u8d77\u52d5\u30fb\u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n",
    "import subprocess\n",
    "import time\n",
    "import ollama  # type: ignore\n",
    "\n",
    "!apt-get install -y -qq zstd\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "process = subprocess.Popen(\n",
    "    [\"ollama\", \"serve\"],\n",
    "    stdout=subprocess.DEVNULL,\n",
    "    stderr=subprocess.DEVNULL,\n",
    ")\n",
    "time.sleep(5)\n",
    "\n",
    "\n",
    "def ollama_pull(model: str) -> None:\n",
    "    \"\"\"Ollama \u30e2\u30c7\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3001\u9032\u6357\u3092\u30a4\u30f3\u30e9\u30a4\u30f3\u8868\u793a\u3059\u308b\u3002\"\"\"\n",
    "    for progress in ollama.pull(model, stream=True):\n",
    "        status = progress.get(\"status\", \"\")\n",
    "        total = progress.get(\"total\") or 0\n",
    "        completed = progress.get(\"completed\") or 0\n",
    "        if total:\n",
    "            line = f\"{status}: {completed / total:.0%}\"\n",
    "        else:\n",
    "            line = status\n",
    "        print(f\"\\r{line:<60}\", end=\"\", flush=True)\n",
    "    print(f\"\\n{model}: Done!\")\n",
    "\n",
    "\n",
    "model_name = \"gpt-oss:20b\"\n",
    "ollama_pull(model_name)\n",
    "!ollama show {model_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`src/` \u3092 Python \u30d1\u30b9\u306b\u8ffd\u52a0**\n",
    "\n",
    "Google Colab \u3067\u306f `notebook/` \u304b\u3089 `src/` \u914d\u4e0b\u306e\u30e2\u30b8\u30e5\u30fc\u30eb\u3092 import \u3059\u308b\u305f\u3081\u3001\n",
    "`sys.path` \u306b `src/` \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u8ffd\u52a0\u3059\u308b\u3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# notebook/ \u306e\u89aa\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\uff08\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30eb\u30fc\u30c8\uff09\u3092\u53d6\u5f97\n",
    "project_root = Path.cwd().parent\n",
    "src_path = str(project_root / \"src\")\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"src path added: {src_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIContainer \u3067\u4f9d\u5b58\u6027\u3092\u7d44\u307f\u7acb\u3066\u3001Gradio UI \u3092\u8d77\u52d5**\n",
    "\n",
    "Clean Architecture \u306e Infrastructure \u5c64\u306b\u3042\u308b `DIContainer` \u304c\u3001\n",
    "\u3059\u3079\u3066\u306e\u4f9d\u5b58\u6027\uff08LLM\u30fbVectorStore\u30fbReranker\u30fbDataLoader\uff09\u3092\u751f\u6210\u3057\u3001\n",
    "\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u30a4\u30f3\u30b8\u30a7\u30af\u30b7\u30e7\u30f3\u3067 `AgentWorkflow` \u3068 `GradioHandler` \u306b\u6ce8\u5165\u3059\u308b\u3002\n",
    "\n",
    "`WorkflowConfig` \u306e\u30cf\u30a4\u30d1\u30fc\u30d1\u30e9\u30e1\u30fc\u30bf\u306f\u3001\u74b0\u5883\u5909\u6570\uff08`RAG_` \u30d7\u30ec\u30d5\u30a3\u30c3\u30af\u30b9\uff09\u3067\u4e0a\u66f8\u304d\u53ef\u80fd\u3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from domain.config import WorkflowConfig\n",
    "from infrastructure.di_container import DIContainer\n",
    "\n",
    "# \u30ed\u30b0\u8a2d\u5b9a\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(name)s: %(message)s\",\n",
    ")\n",
    "\n",
    "# \u8a2d\u5b9a\u3092\u751f\u6210\uff08\u30c7\u30d5\u30a9\u30eb\u30c8\u5024\u307e\u305f\u306f\u74b0\u5883\u5909\u6570\u304b\u3089\u8aad\u307f\u8fbc\u307f\uff09\n",
    "config = WorkflowConfig()\n",
    "\n",
    "# DI \u30b3\u30f3\u30c6\u30ca\u3067\u5168\u4f9d\u5b58\u6027\u3092\u7d44\u307f\u7acb\u3066\n",
    "container = DIContainer(config=config)\n",
    "\n",
    "# Gradio UI \u3092\u751f\u6210\u30fb\u8d77\u52d5\n",
    "ui = container.create_ui()\n",
    "demo = ui.launch()\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}