# 性能改善: spaCy キャッシュ + GradioHandler ストリーミング対応

## 背景

初回実装完了後の Google Colab テストにて、以下2点の性能問題が発覚した。

1. **PDF 読み込みが極端に遅い** — notebook 07 と比較して明確に遅い
2. **チャット応答に思考過程のリアルタイム表示がない** — AgentWorkflow.ainvoke() を単一ブロッキング呼び出ししており、応答完了まで UI が無反応

## 要求内容

### R1: PDF 読み込み速度の改善

- `tokenize()` 関数が呼び出しのたびに `spacy.load()` を実行しており、BM25 インデックス構築時に 214 回のモデルロードが発生していた
- spaCy モデルをモジュールレベルでキャッシュし、初回のみロードするように修正する

### R2: GradioHandler のストリーミング対応

- GradioHandler.respond() が AgentWorkflow.ainvoke() を1回呼ぶだけの構造だったため、思考過程のリアルタイム表示とトークン単位のストリーミング回答ができなかった
- notebook 07 と同様に、各ノード（task_planning → doc_search → summarize → judge → generate_answer）を個別に呼び出し、各ステップで yield して思考過程をリアルタイム表示する
- 最終回答は `llm.astream()` によりトークン単位でストリーミングする

## ユーザーストーリー

- ユーザとして、PDF アップロード後に素早くチャンク登録が完了し、すぐに質問を始められるようにしたい
- ユーザとして、AI の思考過程（タスク分割・検索・要約・判定）がリアルタイムで表示され、回答がトークン単位でストリーミングされることで、応答の進捗を把握したい

## 受け入れ条件

- [x] spaCy モデルのロードが初回1回のみであること
- [x] GradioHandler が各ノードを個別に呼び出し、フェーズごとに思考ログを yield すること
- [x] 最終回答がトークン単位でストリーミングされること
- [x] 停止ボタンで生成を中断できること
- [x] 既存テスト 39 件がすべてパスすること
- [x] Ruff チェックがクリーンであること

## 制約事項

- Clean Architecture の層分離を維持する（GradioHandler は Interface Adapters 層）
- Port（Protocol）を通じて依存性を注入する設計を崩さない
